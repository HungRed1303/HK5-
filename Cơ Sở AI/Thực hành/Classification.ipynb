{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Lab: Phân lớp\n",
    "\n",
    "- MSSV: 22120121    \n",
    "- Họ và tên: Lê Viết Hưng"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Yêu cầu bài tập\n",
    "\n",
    "**Cách làm bài**\n",
    "\n",
    "\n",
    "Bạn sẽ làm trực tiếp trên file notebook này; trong file, từ `TODO` để cho biết những phần mà bạn cần phải làm.\n",
    "\n",
    "Bạn có thể thảo luận ý tưởng cũng như tham khảo các tài liệu, nhưng *code và bài làm phải là của bạn*. \n",
    "\n",
    "Nếu vi phạm thì sẽ bị 0 điểm cho bài tập này.\n",
    "\n",
    "**Cách nộp bài**\n",
    "\n",
    "Trước khi nộp bài, rerun lại notebook (`Kernel` -> `Restart & Run All`).\n",
    "\n",
    "Sau đó, đặt tên notebook bằng `MSSV` của bạn (vd, nếu bạn có MSSV là 1234567 thì bạn đặt tên notebook là `1234567.ipynb`) và nộp ở link trên moodle.\n",
    "\n",
    "**Nội dung bài tập**\n",
    "\n",
    "Trong bài này, bạn sẽ cài đặt 2 thuật toán phân lớp: \n",
    "1. Cây quyết định (Decision tree)\n",
    "2. Gaussian Naive Bayes\n",
    "\n",
    "**Một số lưu ý**\n",
    "1. Chỉ cần phát hiện có dấu hiện có sau chép code sẽ 0 điểm cả lab và có thể dẫn đến không điểm môn học\n",
    "2. Sai format nộp bài sẽ bị trừ 20% số điểm\n",
    "3. Trễ deadline 1 ngày sẽ bị trừ 40% số điểm. Sau 24h kể từ hạn nộp sẽ không nhận bất kì bài nộp bổ sung nào.\n",
    "4. Các thắc mắc về bài tập, các bạn vui lòng liên hệ giáo viên qua email `ntthuhang0131@gmail.com` với tiêu đề `[Cơ sở trí tuệ nhân tạo - CQ2022/22 - Thắc mắc lab 03]`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Thêm thư viện cần thiết"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'matplotlib'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[1], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mmatplotlib\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpyplot\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mplt\u001b[39;00m\n\u001b[0;32m      2\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01msklearn\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m datasets\n\u001b[0;32m      3\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mpandas\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mpd\u001b[39;00m\n",
      "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'matplotlib'"
     ]
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "from sklearn import datasets\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.metrics import accuracy_score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load dữ liệu Iris"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "iris=datasets.load_iris()\n",
    "\n",
    "X=iris.data\n",
    "y=iris.target\n",
    "\n",
    "#split dataset into training data and testing data\n",
    "X_train,X_test,y_train,y_test=train_test_split(X,y,test_size=0.33, random_state=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Cây quyết định (Decision Tree)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.1 Iterative Dichotomiser 3 (ID3) (2 đ)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.1.1 Information Gain"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Thông tin kỳ vọng (entropy):"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$Entropy=-\\sum_{i}^{n}p_ilog_{2}(p_i)$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Hàm entropy đạt giá trị nhỏ nhất nếu có một giá trị $p_i=1$, đạt giá trị lớn nhất nếu tất cả các $p_i$ bằng nhau. Những tính chất này của hàm entropy khiến nó được sử dụng trong việc đo độ hỗn loạn của một phép phân chia của ID3."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def entropy(counts, n_samples):\n",
    "    \"\"\"\n",
    "    Parameters:\n",
    "    -----------\n",
    "    counts: shape (n_classes): list number of samples in each class\n",
    "    n_samples: number of data samples\n",
    "    \n",
    "    -----------\n",
    "    return entropy \n",
    "    \"\"\"\n",
    "    #TODO\n",
    "    \n",
    "    return res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def entropy_of_one_division(division): \n",
    "    \"\"\"\n",
    "    Returns entropy of a divided group of data\n",
    "    Data may have multiple classes\n",
    "    \"\"\"\n",
    "    n_samples = len(division)\n",
    "    n_classes = set(division)\n",
    "    \n",
    "    counts=[]\n",
    "    #count samples in each class then store it to list counts\n",
    "    #TODO:\n",
    "    \n",
    "    \n",
    "    return entropy(counts,n_samples),n_samples\n",
    "\n",
    "\n",
    "def get_entropy(y_predict, y):\n",
    "    \"\"\"\n",
    "    Returns entropy of a split\n",
    "    y_predict is the split decision by cutoff, True/Fasle\n",
    "    \"\"\"\n",
    "    n = len(y)\n",
    "    s_true, n_true = entropy_of_one_division(y[y_predict]) # left hand side entropy\n",
    "    s_false, n_false = entropy_of_one_division(y[~y_predict]) # right hand side entropy\n",
    "    s = n_true/n * s_true + n_false/n * s_false # overall entropy\n",
    "    return s"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Độ lợi thông tin phân lớp tập D theo thuộc tính A:\n",
    "$$ Gain(A)=Entrophy(D)-Entrophy_{A}(D)$$\n",
    "\n",
    "Trong ID3, tại mỗi node, thuộc tính được chọn được xác định dựa trên là thuộc tính khiến cho information gain đạt giá trị lớn nhất.\n",
    "\n",
    "Các thuộc tính của tập Iris đều có giá trị liên tục. Do đó ta cần rời rạc hóa cho từng thuộc tính. Cách đơn giản là sử dụng một ngưỡng `cutoff` chia giá trị của dữ liệu trên mỗi thuộc tính sẽ làm 2 phần: `value<cutoff` và `value>=cutoff`.\n",
    "\n",
    "Để tìm ngưỡng `cutoff` tốt nhất cho mỗi thuộc tính ta lần lượt thay `cutoff` bằng các giá trị của thuộc tính sau đó tính entropy, `cutoff` tốt nhất khi entropy bé nhất.  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.1.2 Decision tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DecisionTreeClassifier:\n",
    "    def __init__(self, tree=None, depth=0):\n",
    "        '''Parameters:\n",
    "        -----------------\n",
    "        tree: decision tree\n",
    "        depth: depth of decision tree after training'''\n",
    "        \n",
    "        self.depth = depth\n",
    "        self.tree=tree\n",
    "    def fit(self, X, y, node={}, depth=0):\n",
    "        '''Parameter:\n",
    "        -----------------\n",
    "        X: training data\n",
    "        y: label of training data\n",
    "        ------------------\n",
    "        return: node \n",
    "        \n",
    "        node: each node represented by cutoff value and column index, value and children.\n",
    "         - cutoff value is thresold where you divide your attribute\n",
    "         - column index is your data attribute index\n",
    "         - value of node is mean value of label indexes, \n",
    "           if a node is leaf all data samples will have same label\n",
    "        \n",
    "        Note that: we divide each attribute into 2 part => each node will have 2 children: left, right.\n",
    "        '''\n",
    "        \n",
    "        #Stop conditions\n",
    "        \n",
    "        #if all value of y are the same \n",
    "        if np.all(y==y[0]):\n",
    "            return {'val':y[0]}\n",
    "\n",
    "        else: \n",
    "            col_idx, cutoff, entropy = self.find_best_split_of_all(X, y)    # find one split given an information gain \n",
    "            y_left = y[X[:, col_idx] < cutoff]\n",
    "            y_right = y[X[:, col_idx] >= cutoff]\n",
    "            node = {'index_col':col_idx,\n",
    "                        'cutoff':cutoff,\n",
    "                   'val':np.mean(y)}\n",
    "            node['left'] = self.fit(X[X[:, col_idx] < cutoff], y_left, {}, depth+1)\n",
    "            node['right'] = self.fit(X[X[:, col_idx] >= cutoff], y_right, {}, depth+1)\n",
    "            self.depth += 1 \n",
    "            self.tree = node\n",
    "            return node\n",
    "    \n",
    "    def find_best_split_of_all(self, X, y):\n",
    "        col_idx = None\n",
    "        min_entropy = 1\n",
    "        cutoff = None\n",
    "        for i, col_data in enumerate(X.T):\n",
    "            entropy, cur_cutoff = self.find_best_split(col_data, y)\n",
    "            if entropy == 0:                   #best entropy\n",
    "                return i, cur_cutoff, entropy\n",
    "            elif entropy <= min_entropy:\n",
    "                min_entropy = entropy\n",
    "                col_idx = i\n",
    "                cutoff = cur_cutoff\n",
    "               \n",
    "        return col_idx, cutoff, min_entropy\n",
    "    \n",
    "    def find_best_split(self, col_data, y):\n",
    "        ''' Parameters:\n",
    "        -------------\n",
    "        col_data: data samples in column'''\n",
    "         \n",
    "        min_entropy = 10\n",
    "\n",
    "        #Loop through col_data find cutoff where entropy is minimum\n",
    "        #TODO\n",
    "      \n",
    "        return min_entropy, cutoff\n",
    "                                               \n",
    "    def predict(self, X):\n",
    "        tree = self.tree\n",
    "        pred = np.zeros(shape=len(X))\n",
    "        for i, c in enumerate(X):\n",
    "            pred[i] = self._predict(c)\n",
    "        return pred\n",
    "    \n",
    "    def _predict(self, row):\n",
    "        cur_layer = self.tree\n",
    "        while cur_layer.get('cutoff'):\n",
    "            if row[cur_layer['index_col']] < cur_layer['cutoff']:\n",
    "                cur_layer = cur_layer['left']\n",
    "            else:\n",
    "                cur_layer = cur_layer['right']\n",
    "        else:\n",
    "            return cur_layer.get('val')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.1.3 Classification on Iris Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = DecisionTreeClassifier()\n",
    "tree = model.fit(X_train, y_train)\n",
    "pred=model.predict(X_train)\n",
    "print('Accuracy of your decision tree model on training data:', accuracy_score(y_train,pred))\n",
    "pred=model.predict(X_test)\n",
    "print('Accuracy of your decision tree model:', accuracy_score(y_test,pred))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.2 CART (Classification and Regression Trees) (2 đ)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Các bạn tự cài đặt lại thuật toán CART và test trên tập dữ liệu Iris (tham khảo cách trình bày ở `phần 1.1`)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.3 Câu hỏi lý thuyết (2 đ)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*Đây là câu hỏi về lý thuyết có thể giúp các bạn buổi sung kiến thức cho các buổi phỏng vấn. Các bạn có thể tham khảo bất kì nguồn nào trừ ChatGPT và có thể thêm hình ảnh minh họa để có câu trả lời rõ ràng và dễ hiểu nhất. Và khi đã tham khảo phải liệt kê tài liệu tham khảo? Trường hợp phát hiện đạo văn bài làm sẽ nhận 0 điểm ngay lập tức.*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 1. So sánh Entropy, Gini Impurity và Variance Reduction trong Decision Tree. Khi nào nên sử dụng mỗi tiêu chí?\n",
    "\n",
    "Câu trả lời:\n",
    "`TODO`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 2. Overfitting trong Decision Tree là gì? Bạn có thể làm gì để giảm thiểu vấn đề này?\n",
    "Câu trả lời:\n",
    "`TODO`\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 3. Decision Tree có phù hợp cho dữ liệu nhiều chiều hoặc dữ liệu không cân bằng không? Tại sao? \n",
    "Câu trả lời:\n",
    "`TODO`\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 4. Nếu bạn có một Decision Tree quá lớn (deep tree), bạn sẽ làm gì để cải thiện khả năng tổng quát của nó?\n",
    "Câu trả lời:\n",
    "`TODO`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Định lý Bayes (4 đ)\n",
    "\n",
    "Định lý Bayes được phát biểu dưới dạng toán học như sau:\n",
    "$$\\begin{equation}\n",
    "P\\left(A|B\\right)= \\dfrac{P\\left(B|A\\right)P\\left(A\\right)}{P\\left(B\\right)}\n",
    "\\end{equation}$$\n",
    "\n",
    "Nếu ta coi $B$ là dữ liệu $\\mathcal{D}$, các thông số cần ước tính $A$ là $w$, ta có:\n",
    "\n",
    "$$ \\begin{align}\n",
    "    \\underbrace{P(w|\\mathcal{D})}_{Posterior}= \\dfrac{1}{\\underbrace{P(\\mathcal{D})}_{Normalization}} \\overbrace{P(\\mathcal{D}|w)}^{\\text{Likelihood}} \\overbrace{P(w)}^{Prior}\n",
    "    \\end{align}\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Naive Bayes\n",
    "Để giúp cho việc tính toán được đơn giản, người ta thường giả sử một cách đơn giản nhất rằng các thành phần của biến ngẫu nhiên $D$ (hay các thuộc tính của dữ liệu $D$) là độc lập với nhau, nếu biết $w$. Tức là:\n",
    "$$P(\\mathcal{D}|w)=\\prod _{i=1}^{d}P(x_i|w)$$\n",
    "\n",
    "$d$: số lượng thuộc tính\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.1 Probability Density Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class pdf:\n",
    "    def __init__(self,hist=None):\n",
    "        '''\n",
    "        A probability density function represented by a histogram\n",
    "        \n",
    "        hist: shape (n,1), n: number of hypotheses\n",
    "        hypo: hypothesis (simply understand as label)\n",
    "        hist[hypo]=P(hypo)\n",
    "        '''\n",
    "        self.hist = hist\n",
    "        \n",
    "    #virtual function\n",
    "    def likelihood(self, data, hypo):\n",
    "        '''Paramters:\n",
    "        data: new data record \n",
    "        hypo: hypothesis (simply understand as label)\n",
    "        ---------\n",
    "        return P(data/hypo)\n",
    "        ''' \n",
    "        raise Exception()\n",
    "            \n",
    "    #update histogram for new data \n",
    "    def update(self, data):\n",
    "        ''' \n",
    "        P(hypo/data)=P(data/hypo)*P(hypo)*(1/P(data))\n",
    "        '''\n",
    "        \n",
    "        #Likelihood * Prior \n",
    "        #TODO\n",
    "       \n",
    "            \n",
    "        #Normalization\n",
    "        \n",
    "        #TODO: s=P(data)\n",
    "        #s=?\n",
    "        \n",
    "        \n",
    "        for hypo in self.hist.keys():\n",
    "            self.hist[hypo] = self.hist[hypo]/s\n",
    "        \n",
    "    def plot_pdf(self):\n",
    "        #plot Histogram\n",
    "        #TODO\n",
    "      \n",
    "    \n",
    "    def maxHypo(self):\n",
    "        #find the hypothesis with maximum probability from hist\n",
    "        #TODO\n",
    "        \n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.2 Classification on Iris Dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Gaussian Naive Bayes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Naive Bayes có thể được mở rộng cho dữ liệu với các thuộc tính có giá trị là số thực, phổ biến nhất bằng cách sử dụng phân phối chuẩn (Gaussian distribution).\n",
    "\n",
    "- Phần mở rộng này được gọi là Gaussian Naive Bayes. Các hàm khác có thể được sử dụng để ước tính phân phối dữ liệu, nhưng Gaussian (hoặc phân phối chuẩn) là dễ nhất để làm việc vì chỉ cần ước tính giá trị trung bình và độ lệch chuẩn từ dữ liệu huấn luyện."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Định nghĩa hàm Gauss "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$ f\\left(x;\\mu,\\sigma \\right)= \\dfrac{1}{\\sigma \\sqrt{2\\pi}} \n",
    "\\exp \\left({-\\dfrac{\\left(x-\\mu\\right)^2}{2 \\sigma^2}}\\right) $$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Gauss(std,mean,x):\n",
    "    #Calculate the Gaussian probability distribution function for x\n",
    "    #TODO \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class NBGaussian(pdf):\n",
    "    def __init__(self, hist=None, std=None, mean=None):\n",
    "        '''Parameters:\n",
    "        \n",
    "        '''\n",
    "        pdf.__init__(self, hist)\n",
    "        self.std=std\n",
    "        self.mean=mean\n",
    "    def likelihood(self,data, hypo):\n",
    "        '''\n",
    "        Returns: P(data/hypo)\n",
    "        -----------------\n",
    "        Naive bayes:\n",
    "            Atributes are assumed to be conditionally independent given the class value.\n",
    "        '''\n",
    "    \n",
    "        std=self.std[hypo]\n",
    "        mean=self.mean[hypo]\n",
    "        res=1\n",
    "        #TODO\n",
    "        #res=res*P(xi/hypo)\n",
    "       \n",
    "            \n",
    "        return res \n",
    "    def fit(self, X,y):\n",
    "        \"\"\"Parameters:\n",
    "        X: training data\n",
    "        y: labels of training data\n",
    "        \"\"\"\n",
    "        n=len(X)\n",
    "        #number of iris species\n",
    "        #TODO\n",
    "       \n",
    "        \n",
    "        hist={}\n",
    "        mean={}\n",
    "        std={}\n",
    "        \n",
    "        #separate  dataset into rows by class\n",
    "        for hypo in range(0,n_species):\n",
    "            #TODO rows=?\n",
    "            \n",
    "            \n",
    "            #histogram for each hypo\n",
    "            #TODO probability=?\n",
    "            \n",
    "            \n",
    "            #Gaussian naive bayes each hypothesis represented by its mean and standard derivation\n",
    "            '''mean and standard derivation should be calculated for each column (or each attribute)'''\n",
    "            #TODO mean[hypo]=?, std[hypo]=?\n",
    "            \n",
    "         \n",
    "\n",
    "        self.mean=mean\n",
    "        self.std=std\n",
    "        self.hist=hist\n",
    "   \n",
    "    def _predict(self, data, plot=False):\n",
    "        \"\"\"\n",
    "        Predict label for only 1 data record\n",
    "        ------------\n",
    "        Parameters:\n",
    "        data: new data record\n",
    "        plot: True: draw histogram after update new record\n",
    "        -----------\n",
    "        return: label of data\n",
    "        \"\"\"\n",
    "        model=NBGaussian(hist=self.hist.copy(),std=self.std.copy(), mean=self.mean.copy())\n",
    "        model.update(data)\n",
    "        if (plot): model.plot_pdf()\n",
    "        return model.maxHypo()\n",
    "    \n",
    "    def predict(self, data):\n",
    "        \"\"\"Parameters:\n",
    "        Data: test data\n",
    "        ----------\n",
    "        return labels of test data\"\"\"\n",
    "        \n",
    "        pred=[]\n",
    "        for x in data:\n",
    "            pred.append(self._predict(x))\n",
    "        return pred"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Vẽ histogram of training data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_1=NBGaussian()\n",
    "model_1.fit(X_train, y_train)\n",
    "model_1.plot_pdf()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Nhận xét chart: `TODO`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#label of y_test[10]\n",
    "print('Label of X_test[10]: ', y_test[10])\n",
    "#update model and show histogram with X_test[10]:\n",
    "\n",
    "print('Our histogram after update X_test[10]: ')\n",
    "model_1._predict(X_test[10],plot=True)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Đánh giá hiệu suất mô hình Gaussian Naive Bayes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred=model_1.predict(X_test)\n",
    "print('Accuracy of your Gaussian Naive Bayes model:', accuracy_score(y_test,pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.3 Một số câu hỏi lí thuyết"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*Đây là câu hỏi về lý thuyết có thể giúp các bạn buổi sung kiến thức cho các buổi phỏng vấn. Các bạn có thể tham khảo bất kì nguồn nào trừ ChatGPT và có thể thêm hình ảnh minh họa để có câu trả lời rõ ràng và dễ hiểu nhất. Và khi đã tham khảo phải liệt kê tài liệu tham khảo? Trường hợp phát hiện đạo văn bài làm sẽ nhận 0 điểm ngay lập tức.*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 1. Trường hợp sử dụng Gaussian Naive Bayes? Nêu chí tiết và cho 3 ứng dụng cụ thể (nêu rõ: input là gì? output là gì? mục tiêu sử dụng?)?\n",
    "\n",
    "Câu trả lời:\n",
    "`TODO`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 2. Có điều kiện bắt buộc nào của dữ liệu đầu vào khi sử dụng Gaussian Naive Bayes không?\n",
    "\n",
    "Câu trả lời:\n",
    "`TODO`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 3. Tại sao Naive Bayes thường được sử dụng trong các bài toán phân loại văn bản (Text Classification)?\n",
    "Câu trả lời : `TODO`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tài liệu tham khảo"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
